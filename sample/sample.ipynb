{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import importlib\n",
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "import json\n",
    "import nltk\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "import clip\n",
    "import kornia\n",
    "import torchvision\n",
    "import skimage.color\n",
    "import random\n",
    "\n",
    "from utils_func import *\n",
    "from html_images import *\n",
    "from sample_func import *\n",
    "from colorizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucky\\Anaconda3\\lib\\site-packages\\torch\\utils\\tensorboard\\__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n",
      "c:\\Users\\lucky\\Anaconda3\\lib\\site-packages\\torch\\utils\\tensorboard\\__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 1024, 16, 16) = 262144 dimensions.\n"
     ]
    }
   ],
   "source": [
    "# Coco model\n",
    "ckpt_file = 'C:/MyFiles/CondTran/finals/bert_coco/logs/bert/epoch=144-step=259999.ckpt'\n",
    "# Imagenet model\n",
    "#ckpt_file = 'C:/MyFiles/CondTran/finals/bert_final/logs/bert/epoch=14-step=142124.ckpt'\n",
    "\n",
    "device = 'cuda:0'\n",
    "colorizer = Colorizer(ckpt_file, device, [256, 256], load_clip=False, load_warper=False)\n",
    "filltran = colorizer.transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(x_gray, topk, strokes):\n",
    "    _, f_gray = filltran.hybrid_vqgan.encode(None, x_gray)\n",
    "    B = f_gray.shape[0]\n",
    "    sample_shape = [16, 16]\n",
    "    rows, cols = f_gray.shape[2:4]\n",
    "\n",
    "    idx_color = filltran.mask_token * torch.ones([B, rows, cols]).to(device).long()\n",
    "\n",
    "    if len(strokes) > 0:\n",
    "        cond = []\n",
    "        cond_indices = []\n",
    "        for stk in strokes:\n",
    "            ind = stk['index']\n",
    "            color = stk['color']\n",
    "            color = torch.Tensor(color).to(device)\n",
    "            color = color / 255.0 * 2.0 - 1.0\n",
    "            for b in range(B):\n",
    "                index = torch.Tensor([b, ind[0]//16, ind[1]//16]).long().to(device)\n",
    "                cond.append(color.unsqueeze(0))\n",
    "                cond_indices.append(index.unsqueeze(0))\n",
    "        cond = torch.cat(cond, axis=0)\n",
    "        cond_indices = torch.cat(cond_indices, axis=0)\n",
    "    else:\n",
    "        cond = None\n",
    "        cond_indices = None\n",
    "\n",
    "    i = 0\n",
    "    for r in range(16):\n",
    "        for c in range(16):\n",
    "            cond_gray = f_gray.clone()\n",
    "            cond_gray = cond_gray.reshape(cond_gray.shape[0], cond_gray.shape[1], -1)\n",
    "            cond_gray = cond_gray.permute(0, 2, 1).contiguous()\n",
    "            # Input color indices\n",
    "            logits = filltran.coltran(idx_color, cond_gray, cond, cond_indices)\n",
    "            logits = logits[:, i, :]\n",
    "            logits = logits.reshape(-1, logits.shape[-1])\n",
    "            logits = filltran.top_k_logits(logits, topk)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            ix = torch.multinomial(probs, num_samples=1)\n",
    "            idx_color[:, r, c] = ix[:, 0]\n",
    "            i += 1\n",
    "\n",
    "    gen = filltran.hybrid_vqgan.decode(idx_color, f_gray)\n",
    "\n",
    "    return gen\n",
    "\n",
    "\n",
    "def getImage(path):\n",
    "    for ext in ['jpg', 'png', 'JPEG']:\n",
    "        file = path + '.' + ext\n",
    "        if os.path.isfile(file):\n",
    "            return Image.open(file).convert('RGB')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling arguments\n",
    "img_dirs = {'imagenet': 'C:\\\\MyFiles\\\\Dataset\\\\imagenet\\\\val5000\\\\val', 'coco': 'C:\\\\MyFiles\\\\Dataset\\\\coco\\\\val2017'}\n",
    "\n",
    "save_dir = 'C:\\\\Users\\\\lucky\\\\Desktop\\\\visualize\\\\raw\\\\temp2'\n",
    "topk = 100\n",
    "num_samples = [5, 5, 5]\n",
    "img_size = [256, 256]\n",
    "sample_size = [img_size[0]//16, img_size[1]//16]\n",
    "\n",
    "html = HTML(save_dir, 'Sample')\n",
    "\n",
    "#with open('C:\\\\Users\\\\lucky\\\\Desktop\\\\visualize\\\\raw\\\\temp.json', 'rb') as f:\n",
    "    #visual_files = json.load(f)\n",
    "\n",
    "visual_files = [{\n",
    "    \"dataset\": \"imagenet\",\n",
    "    \"images\": ['']\n",
    "},\n",
    "{\n",
    "    \"dataset\": \"coco\",\n",
    "    \"images\":['000000467511.jpg']\n",
    "}]\n",
    "\n",
    "for dataset in visual_files:\n",
    "    for f in tqdm(dataset['images']):\n",
    "        if f.endswith('.jpg') or f.endswith('.png') or f.endswith('.JPEG') or f.endswith('.jpeg'):\n",
    "            dname = dataset['dataset']\n",
    "            fname = f.split('.')[0]\n",
    "            I_color = Image.open(os.path.join(img_dirs[dname], f)).convert('RGB')\n",
    "            I_gray = I_color.convert('L')\n",
    "            \n",
    "            gen_imgs = [I_color, I_gray]\n",
    "\n",
    "            x_gray = preprocess(I_gray, img_size).to(device)\n",
    "\n",
    "            comp = getImage(os.path.join('C:\\\\Users\\\\lucky\\\\Desktop\\\\visualize\\\\raw\\\\instcolor', fname))\n",
    "            gen_imgs.append(comp)\n",
    "            comp = getImage(os.path.join('C:\\\\Users\\\\lucky\\\\Desktop\\\\visualize\\\\raw\\\\chromagan', fname))\n",
    "            gen_imgs.append(comp)\n",
    "            comp = getImage(os.path.join('C:\\\\Users\\\\lucky\\\\Desktop\\\\visualize\\\\raw\\\\coltran', fname))\n",
    "            gen_imgs.append(comp)\n",
    "\n",
    "            for n in num_samples:\n",
    "                x_gray_batch = x_gray.repeat(n, 1, 1, 1)\n",
    "                gen = sample(x_gray_batch, topk=topk, strokes=[])\n",
    "                for b in range(gen.shape[0]):\n",
    "                    img = output_to_pil(gen[b])\n",
    "                    img = color_resize(I_gray, img)\n",
    "                    gen_imgs.append(img)\n",
    "            \n",
    "            texts = []\n",
    "            for i in range(np.sum(num_samples)+5):\n",
    "                texts.append(str(i))\n",
    "            texts[0] = fname\n",
    "            texts[1] = 'gray'\n",
    "            texts[2] = 'instcolor'\n",
    "            texts[3] = 'chromagan'\n",
    "            texts[4] = 'coltran'\n",
    "            \n",
    "            save_result(html, index=fname, images=gen_imgs, texts=texts)\n",
    "            html.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplar visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling arguments\n",
    "topk = 100\n",
    "num_samples = [5, 5, 5, 5, 5]\n",
    "img_size = [256, 256]\n",
    "sample_size = [img_size[0]//16, img_size[1]//16]\n",
    "img_path = 'C:\\\\Users\\\\lucky\\\\Desktop\\\\visualize\\\\exemplar\\\\visualize.json'\n",
    "dataset_path = 'C:\\\\MyFiles\\\\Dataset\\\\imagenet\\\\val5000\\\\val'\n",
    "ref_path = 'C:\\\\MyFiles\\\\Comparison\\\\exemplar\\\\final_exp\\\\images\\\\1'\n",
    "save_dir = 'C:\\\\Users\\\\lucky\\\\Desktop\\\\visualize\\\\exemplar\\\\exp2'\n",
    "\n",
    "html = HTML(save_dir, 'Sample')\n",
    "\n",
    "# Load strokes\n",
    "with open(img_path, 'r') as file:\n",
    "    all_files = json.load(file)\n",
    "\n",
    "pbar = tqdm(all_files)\n",
    "\n",
    "for filename in pbar:\n",
    "    name = filename.split('.')[0]\n",
    "    gen_imgs = []\n",
    "\n",
    "    I_color = Image.open(os.path.join(dataset_path, filename.replace('.png', '.JPEG'))).convert('RGB')\n",
    "    I_gray = I_color.convert('L')\n",
    "    I_ref = Image.open(os.path.join(ref_path, filename)).convert('RGB')\n",
    "\n",
    "    gen_imgs.append(I_color)\n",
    "    gen_imgs.append(I_ref)\n",
    "\n",
    "    strokes, warped_img = colorizer.get_strokes_from_exemplar(I_gray, I_ref)\n",
    "    gen_imgs.append(warped_img.resize(I_color.size))\n",
    "\n",
    "    draw_img = draw_strokes(I_gray, img_size, strokes)\n",
    "    gen_imgs.append(draw_img.resize(I_color.size))\n",
    "\n",
    "    gen_imgs.append(Image.open(f'C:\\\\MyFiles\\\\Comparison\\\\exemplar\\\\deep_exemplar\\\\{filename}').convert('RGB'))\n",
    "    gen_imgs.append(Image.open(f'C:\\\\MyFiles\\\\Comparison\\\\exemplar\\\\exemplar_video\\\\{filename}').convert('RGB'))\n",
    "\n",
    "    x_gray = preprocess(I_gray, img_size).to(device)\n",
    "    \n",
    "    for n in num_samples:\n",
    "        x_gray_batch = x_gray.repeat(n, 1, 1, 1)\n",
    "        gen = sample(x_gray_batch, topk=topk, strokes=strokes)\n",
    "        for b in range(gen.shape[0]):\n",
    "            img = output_to_pil(gen[b])\n",
    "            img = color_resize(I_gray, img)\n",
    "            gen_imgs.append(img)\n",
    "        \n",
    "    texts = []\n",
    "    for i in range(np.sum(num_samples)+6):\n",
    "        texts.append(str(i))\n",
    "    texts[0] = name\n",
    "\n",
    "    save_result(html, index=name, images=gen_imgs, texts=texts)\n",
    "    html.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stroke Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling arguments\n",
    "img_dirs = {'imagenet': 'C:\\\\MyFiles\\\\Comparison\\\\stroke\\\\final_stroke_imagenet\\\\images\\\\0', \n",
    "            'coco': 'C:\\\\MyFiles\\\\Comparison\\\\stroke\\\\final_stroke_coco\\\\images\\\\0'}\n",
    "with open('C:\\\\MyFiles\\\\CondTran\\\\data\\\\imagenet_strokes.json', 'rb') as f:\n",
    "    imagenet_strokes = json.load(f)\n",
    "with open('C:\\\\MyFiles\\\\CondTran\\\\data\\\\coco_strokes.json', 'rb') as f:\n",
    "    coco_strokes = json.load(f)\n",
    "num_strokes = [2, 16]\n",
    "\n",
    "imagenet_sample_strokes = []\n",
    "random.seed(100)\n",
    "for file in imagenet_strokes:\n",
    "    strokes = file['strokes']\n",
    "    n_strokes = random.randint(num_strokes[0], num_strokes[1])\n",
    "    n_strokes = min(n_strokes, len(strokes))\n",
    "    strokes = random.sample(strokes, k=n_strokes)\n",
    "    imagenet_sample_strokes.append(strokes)\n",
    "\n",
    "coco_sample_strokes = []\n",
    "random.seed(100)\n",
    "for file in coco_strokes:\n",
    "    strokes = file['strokes']\n",
    "    n_strokes = random.randint(num_strokes[0], num_strokes[1])\n",
    "    n_strokes = min(n_strokes, len(strokes))\n",
    "    strokes = random.sample(strokes, k=n_strokes)\n",
    "    coco_sample_strokes.append(strokes)\n",
    "\n",
    "strokes = {'imagenet': imagenet_sample_strokes, 'coco': coco_sample_strokes}\n",
    "\n",
    "\n",
    "save_dir = 'C:\\\\Users\\\\lucky\\\\Desktop\\\\visualize\\\\stroke\\\\ours3'\n",
    "topk = 200\n",
    "num_samples = [5, 5, 5,5,5,5,5,5,5,5,5,5]\n",
    "img_size = [256, 256]\n",
    "sample_size = [img_size[0]//16, img_size[1]//16]\n",
    "\n",
    "html = HTML(save_dir, 'Sample')\n",
    "\n",
    "with open('C:\\\\Users\\\\lucky\\\\Desktop\\\\visualize\\\\stroke\\\\visualize.json', 'rb') as f:\n",
    "    visual_files = json.load(f)\n",
    "\n",
    "allfiles = []\n",
    "for files in visual_files:\n",
    "    for f in tqdm(files['images']):\n",
    "        fname = f.split('.')[0]\n",
    "        dataset = files['dataset']\n",
    "        I_color = Image.open(os.path.join(img_dirs[dataset], f)).convert('RGB')\n",
    "        I_gray = I_color.convert('L')\n",
    "        \n",
    "        gen_imgs = [I_color, I_gray]\n",
    "\n",
    "        stk = strokes[dataset][int(fname)]\n",
    "\n",
    "        draw_img = draw_strokes(I_gray, img_size, stk)\n",
    "        gen_imgs.append(draw_img)\n",
    "\n",
    "        x_gray = preprocess(I_gray, img_size).to(device)\n",
    "\n",
    "        for n in num_samples:\n",
    "            x_gray_batch = x_gray.repeat(n, 1, 1, 1)\n",
    "            gen = sample(x_gray_batch, topk=topk, strokes=stk)\n",
    "            for b in range(gen.shape[0]):\n",
    "                img = output_to_pil(gen[b])\n",
    "                img = color_resize(I_gray, img)\n",
    "                gen_imgs.append(img)\n",
    "        \n",
    "        texts = []\n",
    "        for i in range(np.sum(num_samples)+3):\n",
    "            texts.append(str(i))\n",
    "        texts[0] = fname\n",
    "\n",
    "        save_result(html, index=fname, images=gen_imgs, texts=texts)\n",
    "        html.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling arguments\n",
    "topk = 100\n",
    "num_samples = [1]\n",
    "img_size = [256, 256]\n",
    "sample_size = [img_size[0]//16, img_size[1]//16]\n",
    "file_path = 'C:\\\\Users\\\\lucky\\\\Desktop\\\\colorization_results\\\\text\\\\visualize.json'\n",
    "dataset_path = 'C:\\\\Users\\\\lucky\\\\Desktop\\\\colorization_results\\\\text\\\\final_text_old_color\\\\images\\\\0'\n",
    "save_dir = 'C:\\\\Users\\\\lucky\\\\Desktop\\\\More_results\\\\text\\\\ours_coco_text'\n",
    "\n",
    "html = HTML(save_dir, 'Sample')\n",
    "\n",
    "with open('C:\\\\MyFiles\\\\CondTran\\\\data\\\\all_text_strokes.json', 'rb') as f:\n",
    "    images = json.load(f)\n",
    "\n",
    "# Load strokes\n",
    "with open(file_path, 'r') as file:\n",
    "    all_files = json.load(file)\n",
    "\n",
    "pbar = tqdm(all_files)\n",
    "\n",
    "for filename in pbar:\n",
    "    index = filename.split('.png ')[0]\n",
    "    name = images[int(index)]['image'].split('.')[0]\n",
    "    caption = filename.split('.png ')[1]\n",
    "    gen_imgs = []\n",
    "\n",
    "    I_color = Image.open(os.path.join(dataset_path, name+'.png')).convert('RGB')\n",
    "    I_gray = I_color.convert('L')\n",
    "\n",
    "    gen_imgs.append(I_color)\n",
    "\n",
    "    strokes, heatmaps = colorizer.get_strokes_from_clip(I_gray, caption)\n",
    "\n",
    "    if len(heatmaps) > 1:\n",
    "        heat = []\n",
    "        for h in heatmaps:\n",
    "            heat.append(np.array(h))\n",
    "        heat = np.concatenate(heat, axis=1)\n",
    "        heat = Image.fromarray(heat)\n",
    "    else:\n",
    "        heat = heatmaps[0]\n",
    "    gen_imgs.append(heat)\n",
    "\n",
    "    draw_img = draw_strokes(I_gray, img_size, strokes)\n",
    "    gen_imgs.append(draw_img.resize(I_color.size))\n",
    "\n",
    "    x_gray = preprocess(I_gray, img_size).to(device)\n",
    "\n",
    "    for n in num_samples:\n",
    "        x_gray_batch = x_gray.repeat(n, 1, 1, 1)\n",
    "        gen = sample(x_gray_batch, topk=topk, strokes=strokes)\n",
    "        for b in range(gen.shape[0]):\n",
    "            img = output_to_pil(gen[b])\n",
    "            img = color_resize(I_gray, img)\n",
    "            gen_imgs.append(img)\n",
    "        \n",
    "    texts = []\n",
    "    for i in range(np.sum(num_samples)+3):\n",
    "        texts.append(str(i))\n",
    "    texts[0] = index\n",
    "    texts[1] = caption\n",
    "\n",
    "    save_result(html, index=index, images=gen_imgs, texts=texts)\n",
    "    html.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample old photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212/212 [9:38:42<00:00, 163.79s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Sampling arguments\n",
    "img_dir = 'C:\\\\Users\\\\lucky\\\\Desktop\\\\test_img\\\\old_photos'\n",
    "save_dir = 'C:\\\\Users\\\\lucky\\\\Desktop\\\\legacy\\\\uncond'\n",
    "topk = 100\n",
    "num_samples = [5, 5, 5, 5]\n",
    "img_size = [256, 256]\n",
    "sample_size = [img_size[0]//16, img_size[1]//16]\n",
    "\n",
    "html = HTML(save_dir, 'Sample')\n",
    "files = os.listdir(img_dir)\n",
    "\n",
    "for i, f in enumerate(tqdm(files)):\n",
    "    if f.endswith('.jpg') or f.endswith('.png') or f.endswith('.JPEG') or f.endswith('.jpeg'):\n",
    "        fname = f.split('.')[0]\n",
    "        I_color = Image.open(os.path.join(img_dir, f)).convert('RGB')\n",
    "        I_gray = I_color.convert('L')\n",
    "        \n",
    "        gen_imgs = [I_color, I_gray]\n",
    "\n",
    "        x_gray = preprocess(I_gray, img_size).to(device)\n",
    "\n",
    "        for n in num_samples:\n",
    "            x_gray_batch = x_gray.repeat(n, 1, 1, 1)\n",
    "            gen = sample(x_gray_batch, topk=topk, strokes=[])\n",
    "            for b in range(gen.shape[0]):\n",
    "                img = output_to_pil(gen[b])\n",
    "                img = color_resize(I_gray, img)\n",
    "                gen_imgs.append(img)\n",
    "        \n",
    "        texts = []\n",
    "        for n in range(np.sum(num_samples)+2):\n",
    "            texts.append(str(n))\n",
    "        texts[0] = str(i)\n",
    "        texts[1] = fname\n",
    "        \n",
    "        save_result(html, index=i, images=gen_imgs, texts=texts)\n",
    "        html.save()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d703c633b54b2fa5838b43c4e4963eee49000d73a8d9f4372c69dbdf8920ce3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
