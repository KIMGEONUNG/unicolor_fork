{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import importlib\n",
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "import json\n",
    "import nltk\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "import clip\n",
    "import kornia\n",
    "import torchvision\n",
    "import skimage.color\n",
    "import random\n",
    "\n",
    "from utils_func import *\n",
    "from html_images import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--device', type=str, default='cuda:0')\n",
    "\n",
    "parser.add_argument('--root_dir', type=str, default='C:/MyFiles/CondTran/finals/quant')\n",
    "parser.add_argument('--log_dir', type=str, default='logs/bert_quant')\n",
    "parser.add_argument('--step', type=str, default='142124')\n",
    "\n",
    "# Load transformer\n",
    "args = parser.parse_args(args=[])\n",
    "os.chdir(args.root_dir)\n",
    "sys.path.append(args.root_dir)\n",
    "module = importlib.import_module(f'filltran.models.colorization')\n",
    "args.fill_model = getattr(module, 'Colorization')\n",
    "filltran = load_model(args.fill_model, args.log_dir, args.step).to(args.device).eval().requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(x_gray, topk, prior=None):\n",
    "    _, idx_gray = filltran.hybrid_vqgan.encode(None, x_gray)\n",
    "    B = idx_gray.shape[0]\n",
    "    sample_shape = [16, 16]\n",
    "    idx_gray = idx_gray.reshape(B, 16, 16)\n",
    "    rows, cols = idx_gray.shape[1:3]\n",
    "\n",
    "    if prior == None:\n",
    "        idx_color = filltran.mask_token * torch.ones([1, rows, cols]).to(idx_gray.device).long()\n",
    "    else:\n",
    "        idx_color = prior\n",
    "\n",
    "    i = 0\n",
    "    for r in range(16):\n",
    "        for c in range(16):\n",
    "            # Input color indices\n",
    "            logits = filltran.coltran(idx_color, idx_gray, None, None)\n",
    "            logits = logits[:, i, :]\n",
    "            logits = logits.reshape(-1, logits.shape[-1])\n",
    "            logits = filltran.top_k_logits(logits, topk)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            ix = torch.multinomial(probs, num_samples=1)\n",
    "            idx_color[:, r, c] = ix\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    gen = filltran.hybrid_vqgan.decode(idx_color, idx_gray)\n",
    "\n",
    "    return gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample dataset (raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling arguments\n",
    "img_dir = 'C:\\\\MyFiles\\\\Dataset\\\\imagenet\\\\val5000\\\\val'\n",
    "save_dir = 'C:\\\\Users\\\\lucky\\\\Desktop\\\\bert_quant'\n",
    "topk = 100\n",
    "num_samples = 1\n",
    "img_size = [256, 256]\n",
    "sample_size = [img_size[0]//16, img_size[1]//16]\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "pbar = tqdm(enumerate(os.listdir(img_dir)))\n",
    "for i, filename in pbar:\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.JPEG') or filename.endswith('.jpeg'):\n",
    "        name = filename.split('.')[0]\n",
    "        I_color = Image.open(os.path.join(img_dir, filename)).convert('RGB')\n",
    "        I_gray = I_color.convert('L')\n",
    "\n",
    "        x_color = preprocess(I_color, img_size).to(args.device)\n",
    "        x_gray = preprocess(I_gray, img_size).to(args.device)\n",
    "\n",
    "        for n in range(num_samples):\n",
    "            gen = sample(x_gray, topk, prior=None)\n",
    "            gen = output_to_pil(gen[0])\n",
    "            gen_resize = color_resize(I_gray, gen)\n",
    "            gen_resize.save(os.path.join(save_dir, name+'.png'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
